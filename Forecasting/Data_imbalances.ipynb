{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "\n",
    "# machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# data manipulation and signal processing\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import scipy.stats as ss\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "\n",
    "\n",
    "# path = \"/content/drive/Shareddrives/covid.eng.pdn.ac.lk/COVID-AI (PG)/spatio_temporal/Covid19_DL_Forecasting_Codes\"\n",
    "# os.chdir(path)\n",
    "sys.path.insert(0, os.path.join(sys.path[0], '..'))\n",
    "from utils.plots import bar_metrics, plot_prediction\n",
    "from utils.functions import split_into_pieces_inorder,split_into_pieces_random,create_dataset_random, distance, convert_lon_lat_to_adjacency_matrix \n",
    "from utils.data_loader import load_data, per_million, get_daily\n",
    "from utils.data_splitter import split_on_region_dimension, split_on_time_dimension\n",
    "from utils.smoothing_functions import O_LPF,NO_LPF,O_NDA,NO_NDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = True\n",
    "DATASET = \"Sri Lanka\" # \"Texas\" \"USA\" \"Global\"\n",
    "# DATASET = \"Texas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLdSq6qx6J83"
   },
   "source": [
    "Required variables:\n",
    "\n",
    "*   **region_names** - Names of the unique regions.\n",
    "*   **confirmed_cases** - 2D array. Each row should corresponds to values in 'region_names'. Each column represents a day. Columns should be in ascending order. (Starting day -> Present)\n",
    "*   **daily_cases** - confirmed_cases.diff()\n",
    "*   **population** - Population in 'region'\n",
    "*   **features** - Features of the regions. Each column is a certain feature.\n",
    "*   **START_DATE** - Starting date of the data DD/MM/YYYY\n",
    "*   **n_regions** Number of regions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_data(DATASET,path=\"../Datasets\")\n",
    "region_names=d[\"region_names\"] \n",
    "confirmed_cases=d[\"confirmed_cases\"] \n",
    "daily_cases=d[\"daily_cases\"] \n",
    "features=d[\"features\"] \n",
    "START_DATE=d[\"START_DATE\"] \n",
    "n_regions=d[\"n_regions\"] \n",
    "\n",
    "population = features[\"Population\"]\n",
    "for i in range(len(population)):\n",
    "    print(\"{:.2f}%\".format(confirmed_cases[i,:].max()/population[i]*100), region_names[i])\n",
    "\n",
    "days = confirmed_cases.shape[1]\n",
    "\n",
    "print(f\"Total population {population.sum()/1e6:.2f}M, regions:{n_regions}, days:{days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing data imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(segments, data):\n",
    "    bounds = []\n",
    "    count = []\n",
    "    idx = []\n",
    "    for i in range(segments):\n",
    "        data = (data - np.amin(data))\n",
    "        bounds.append(np.round((i+1)*np.amax(data)/segments,3))\n",
    "        if i==0:\n",
    "            ineq = data <= bounds[i]\n",
    "        elif i==(segments-1):\n",
    "            ineq = data > bounds[i-1]\n",
    "        else:\n",
    "            ineq = (data > bounds[i-1])*(data <= bounds[i])\n",
    "        count.append(np.sum(ineq))\n",
    "        idx.append(np.reshape(np.array(np.where(ineq)),[-1,]))\n",
    "    count = np.array(count).astype(int)\n",
    "    bounds = np.array(bounds).astype(np.float64)\n",
    "    return count, bounds, idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "train_end = 100\n",
    "plot_state = 1\n",
    "\n",
    "dataset = np.copy(daily_cases)\n",
    "dataset_norm = np.zeros_like(dataset)\n",
    "for i in range(daily_cases.shape[0]):\n",
    "    dataset_norm[i,:] = dataset[i,:]/np.amax(dataset[i,:])\n",
    "\n",
    "alldata_train = dataset_norm[:,0:train_end]\n",
    "\n",
    "samples_all = np.zeros([alldata_train.shape[0], alldata_train.shape[1]-input_size, input_size])\n",
    "samples_mean = np.zeros([alldata_train.shape[0], alldata_train.shape[1]-input_size])\n",
    "\n",
    "# evaluating optimal number of segments for each district\n",
    "segment_array = [2,3,4,5,6,7,8,9,10]\n",
    "segment_dist = []\n",
    "if plot_state == 1:\n",
    "    plt.figure(figsize=(5*6,5*4))\n",
    "for i in range(samples_all.shape[0]):\n",
    "    for k in range(samples_all.shape[1]):\n",
    "        samples_all[i,k,:] = alldata_train[i,k:k+input_size]\n",
    "        samples_mean[i,k] = np.mean(samples_all[i,k,:])\n",
    "    all_counts = []\n",
    "    count_score = []\n",
    "    # evaluating the count score for each district\n",
    "    for n in range(len(segment_array)):    \n",
    "        segments = segment_array[n]\n",
    "        [count, bounds, idx] = get_count(segments, samples_mean[i,:])              \n",
    "        all_counts.append(np.amin(count)*len(count))\n",
    "        count_score.append((all_counts[n]**1)*(n+1))\n",
    "    if plot_state ==1:\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.plot(segment_array,all_counts/np.amax(all_counts),linewidth=2)\n",
    "        plt.plot(segment_array,count_score/np.amax(count_score),linewidth=2)\n",
    "        plt.legend(['normalised total counts','segment score'])\n",
    "        plt.title('dist: '+region_names[i]+'  segments: '+str(segment_array[np.argmax(count_score)])+'  samples: '+str(all_counts[np.argmax(count_score)]))\n",
    "    segment_dist.append(segment_array[np.argmax(count_score)]) \n",
    "segment_dist = np.array(segment_dist).astype(int)\n",
    "if plot_state ==1:    \n",
    "    plt.show()\n",
    "\n",
    "print('segments per district= ', segment_dist)\n",
    "\n",
    "idx_rand_all = []\n",
    "for i in range(samples_all.shape[0]):\n",
    "    data = samples_mean[i,:]\n",
    "    segments = segment_dist[i]\n",
    "    [count_dist, bounds_dist, idx_dist] = get_count(segments, data)\n",
    "    n_per_seg = np.amin(count_dist)\n",
    "    data_new = []\n",
    "    idx_rand = np.zeros([segments,n_per_seg])\n",
    "    for k in range(segments):\n",
    "        idx_temp = list(idx_dist[k])\n",
    "        idx_rand[k,:] = random.sample(idx_temp,n_per_seg)\n",
    "    idx_rand = np.reshape(idx_rand, [-1,])\n",
    "    idx_rand_all.append(idx_rand)\n",
    "print(len(idx_rand_all))\n",
    "\n",
    "# undersampling using optimal number of segments\n",
    "for i in range(samples_all.shape[0]):\n",
    "    data = samples_mean[i,:]\n",
    "    segments = segment_dist[i]\n",
    "    [count_dist, bounds_dist, idx_dist] = get_count(segments, data)\n",
    "    n_per_seg = np.amin(count_dist)\n",
    "    data_new = []\n",
    "    idx_rand = np.zeros([segments,n_per_seg])\n",
    "    for k in range(segments):\n",
    "        idx_temp = list(idx_dist[k])\n",
    "#         print(idx_temp)\n",
    "        idx_rand[k,:] = random.sample(idx_temp,n_per_seg)\n",
    "    idx_rand = np.reshape(idx_rand, [-1,])\n",
    "    print(region_names[i], idx_rand.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
